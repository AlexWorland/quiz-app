services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: quiz-postgres
    environment:
      POSTGRES_USER: quiz
      POSTGRES_PASSWORD: quiz
      POSTGRES_DB: quiz
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U quiz"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - quiz-network

  # MinIO - S3-compatible object storage for avatars
  minio:
    image: minio/minio:RELEASE.2024-12-13T22-19-12Z
    container_name: quiz-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10s
    networks:
      - quiz-network

  # MinIO bucket initialization
  minio-init:
    image: minio/mc:latest
    container_name: quiz-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/avatars --ignore-existing;
      mc anonymous set download myminio/avatars;
      exit 0;
      "
    networks:
      - quiz-network

  # Rust Backend (Development)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: quiz-backend
    environment:
      DATABASE_URL: postgres://quiz:quiz@postgres:5432/quiz
      JWT_SECRET: ${JWT_SECRET:-development-secret-change-in-production}
      JWT_EXPIRY_HOURS: ${JWT_EXPIRY_HOURS:-24}
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      MINIO_BUCKET: avatars
      DEFAULT_AI_PROVIDER: ${DEFAULT_AI_PROVIDER:-claude}
      DEFAULT_STT_PROVIDER: ${DEFAULT_STT_PROVIDER:-deepgram}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      DEEPGRAM_API_KEY: ${DEEPGRAM_API_KEY:-}
      ASSEMBLYAI_API_KEY: ${ASSEMBLYAI_API_KEY:-}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama2}
      RUST_LOG: ${RUST_LOG:-info}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:-32-byte-secret-key-change-me!!!}
      RUST_ENV: ${RUST_ENV:-development}
      CORS_ALLOWED_ORIGINS: ${CORS_ALLOWED_ORIGINS:-http://localhost:5173,http://localhost:3000}
      ENABLE_STREAMING_TRANSCRIPTION: ${ENABLE_STREAMING_TRANSCRIPTION:-false}
      ENABLE_AI_QUALITY_SCORING: ${ENABLE_AI_QUALITY_SCORING:-false}
      CANVAS_SYNC_LIMIT: ${CANVAS_SYNC_LIMIT:-100}
    ports:
      - "8081:8080"  # Map host port 8081 to container port 8080
    volumes:
      - ./backend:/app
      - backend_target:/app/target
      - cargo_cache:/usr/local/cargo/registry
    depends_on:
      postgres:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command: cargo run
    networks:
      - quiz-network

  # React Frontend (Development)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: quiz-frontend
    environment:
      # Use localhost for browser (runs outside Docker), vite proxy handles internal routing
      VITE_API_URL: ${VITE_API_URL:-http://localhost:8081}
      VITE_WS_URL: ${VITE_WS_URL:-ws://localhost:8081}
      DOCKER_ENV: 'true'  # Signal to vite.config.ts to use Docker networking
      NODE_ENV: development
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
      - frontend_node_modules:/app/node_modules
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5173/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command: npm run dev -- --host 0.0.0.0
    networks:
      - quiz-network

  # Ollama - Local LLM (optional, use with --profile local-llm)
  ollama:
    image: ollama/ollama:0.5.4
    container_name: quiz-ollama
    profiles:
      - local-llm
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - quiz-network
    # Fallback for non-GPU systems - comment out deploy section above

  # Ollama model initialization (pulls llama2 on first run)
  ollama-init:
    image: ollama/ollama:0.5.4
    container_name: quiz-ollama-init
    profiles:
      - local-llm
    depends_on:
      - ollama
    entrypoint: >
      /bin/sh -c "
      sleep 10;
      ollama pull llama2;
      exit 0;
      "
    environment:
      OLLAMA_HOST: ollama:11434
    networks:
      - quiz-network

volumes:
  postgres_data:
  minio_data:
  ollama_data:
  backend_target:
  cargo_cache:
  frontend_node_modules:

networks:
  quiz-network:
    name: quiz-network
    driver: bridge
